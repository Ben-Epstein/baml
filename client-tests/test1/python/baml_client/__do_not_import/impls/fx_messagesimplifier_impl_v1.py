# This file is generated by the BAML compiler.
# Do not edit this file directly.
# Instead, edit the BAML files and recompile.
#
# BAML version: 0.0.1
# Generated Date: __DATE__
# Generated by: vbv

# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long

from ..clients.client_azure_default import AZURE_DEFAULT
from ..functions.fx_messagesimplifier import BAMLMessageSimplifier
from ..types.classes.cls_conversation import Conversation
from ..types.classes.cls_message import Message
from ..types.enums.enm_messagesender import MessageSender
from baml_core._impl.deserializer import Deserializer


# Impl: v1
# Client: AZURE_DEFAULT
# An implementation of .


__prompt_template = """\
Given a chat conversation between a human and ai
simplify the most recent message from the human into a single sentence that includes all prior relevant context. Don't include any previously answered questions. 

{arg}

Most Recent Message:
{arg}

Simplified message:
Human:\
"""

__input_replacers = {
    "arg"
}


# We ignore the type here because baml does some type magic to make this work
# for inline SpecialForms like Optional, Union, List.
__deserializer = Deserializer[str](str)  # type: ignore


@BAMLMessageSimplifier.register_impl("v1")
async def v1(arg: Conversation, /) -> str:
    updates = {k: k.format(arg=arg) for k in __input_replacers}

    prompt = str(__prompt_template)
    for k, v in updates.items():
        prompt = prompt.replace(k, v)

    response = await AZURE_GPT4.run_prompt(prompt)
    return __deserializer.from_string(response.generated)
