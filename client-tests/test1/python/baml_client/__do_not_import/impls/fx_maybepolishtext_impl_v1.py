# This file is generated by the BAML compiler.
# Do not edit this file directly.
# Instead, edit the BAML files and recompile.
#
# BAML version: 0.0.1
# Generated Date: __DATE__
# Generated by: vbv

# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long

from ..clients.client_azure_gpt4 import AZURE_GPT4
from ..functions.fx_maybepolishtext import BAMLMaybePolishText
from ..types.classes.cls_conversation import Conversation
from ..types.classes.cls_improvedresponse import ImprovedResponse
from ..types.classes.cls_message import Message
from ..types.classes.cls_proposedmessage import ProposedMessage
from baml_core._impl.deserializer import Deserializer


# Impl: v1
# Client: AZURE_GPT4
# An implementation of .


__prompt_template = """\
Given a conversation with a resident, consider improving the response previously shown.

Good responses are amiable and direct.

Do not use affirmative or negative unless the question is a yes or no question.

Thread until now:
{@input.conversation.as_str}

Previous Response: {@input.generated_response}

Output JSON:
{@ImprovedResponse.json}

JSON:\
"""


# We ignore the type here because baml does some type magic to make this work
# for inline SpecialForms like Optional, Union, List.
__deserializer = Deserializer[ImprovedResponse](ImprovedResponse)  # type: ignore


@BAMLMaybePolishText.register_impl("v1")
async def v1(arg: ProposedMessage, /) -> ImprovedResponse:
    prompt = __prompt_template.format(arg=arg)
    response = await AZURE_GPT4.run_prompt(prompt)
    return __deserializer.from_string(response.generated)
